analysis_outputs artifact catalog
=================================

Overview (analysis)
-------------------
Artifacts in `analysis_outputs/analysis` are generated by running:
    source .venv/bin/activate
    python -m src.analysis.run_pipeline

Analysis Figures (`analysis/figures/`)
--------------------------------------
PNG visualisations grouped by topic. Nested folders collect batches of related images.

- `class_imbalance_confusion_matrix.png`: confusion matrix from the class imbalance baseline.
- `data_quality_duplicates_train/` *group_###.png*: duplicate image groups from train split (one panel per hash collision, top 20).
- `data_quality_duplicates_val/` *group_###.png*: duplicate groups for validation split (top 20).
- `distribution_comparison_plots.png`: bundled distributions covering pixel, edge, and LBP comparisons.
- `feature_gradcam/` *gradcam_##.png*: Grad-CAM overlays highlighting salient regions (12 samples).
- `feature_interclass_similarity.png`: heatmap of cosine similarity between class centroids.
- `feature_multiscale_edge_density.png`: edge density trends across scales for each split.
- `flip_differences.png`: histograms of horizontal/vertical flip differences (geometric diagnostics).
- `freq_avg_spectrum_{train,val,test}.png`: average log-spectrum visualisations per split.
- `frequency_analysis.png`: low/high frequency trend comparison across splits.
- `label_distribution.png`: bar chart comparing train vs. val class counts.
- `latent_tsne.png`: PCAâ†’t-SNE embedding plot illustrating class separation.
- `perturbations_train_*.png.png`: side-by-side original vs. perturbed examples from robustness probes (one file per sampled image).
- `robustness_adversarial_samples/` *sample_###_#.png*: clean vs. adversarial vs. diff panels for PGD attacks (12 samples).
- `robustness_occlusion/` *occlusion_##.png*: occlusion sensitivity heatmaps (8 samples).
- `test_characterization_edge_hist.png`: edge density distribution comparison across splits.
- `test_characterization_lbp_hist.png`: LBP histogram comparison across splits.
- `test_characterization_pixel_hist.png`: pixel intensity distribution comparison across splits.
- `test_grid.png`: sampled test images (when manifest is available).
- `test_pixel_histogram.png`: legacy histogram from earlier pixel stats run.
- `train_grid.png`, `val_grid.png`: sampled image grids per split (quality checks).
- `train_pixel_histogram.png`, `val_pixel_histogram.png`: pixel intensity histograms for train/val splits.

Analysis Reports (`analysis/reports/`)
--------------------------------------
JSON artifacts and logs containing metrics summaries.

- `class_imbalance_summary.json`: overall accuracy and sampling details for imbalance baseline.
- `class_statistics.json`: consolidated per-class and pixel statistics bundle produced for Task A deliverables.
- `data_quality_duplicates_{train,val}.json`: per-hash duplicate listings for each split.
- `data_quality_summary.json`: rollup of duplicate stats and suspect counts.
-- `feature_exploration_summary.json`: top-level parameters and final validation accuracy for feature exploration.
-- `feature_training_history.json`: loss/accuracy curves recorded during feature extractor training.
-- `label_distribution.json`: class counts and proportions for train/val splits.
-- `latent_structure.json`: explained variance ratios from PCA feeding t-SNE.
-- `pipeline.log`: timestamped execution log for the most recent pipeline run.
-- `robustness_adversarial_results.json`: accuracy under FGSM and PGD attacks at multiple epsilons.
-- `robustness_adversarial_training.json`: training history and clean accuracy for the adversarial baseline model.
-- `robustness_frequency_metrics.json`: aggregated low/high frequency energies per split.
-- `test_characterization_shift_metrics.json`: KL/Wasserstein shift statistics plus edge deltas.
-- `train_image_summary.json`, `val_image_summary.json`: aggregate pixel statistics per split.
-- `train_missing_files.json`, `val_missing_files.json`: lists of label entries without matching image files (should be empty).

CSV exports of structured metrics for spreadsheet or notebook use.

- `class_imbalance_confusion_matrix.csv`: confusion matrix (row-normalised values) for the imbalance baseline.
- `class_imbalance_per_class_accuracy.csv`: per-class counts and validation accuracy.
- `data_quality_duplicate_summary.csv`: summary of perceptual-hash duplicate groups per split.
- `data_quality_suspect_labels.csv`: low-confidence or mismatched predictions flagged for label review.
- `feature_class_centroids.csv`: centroid vectors for each class in the embedding space.
- `feature_interclass_similarity.csv`: cosine similarity matrix between class centroids.
- `feature_multiscale_stats.csv`: multi-scale intensity and edge metrics across splits.
- `geometric_stats.csv`: edge density and flip-difference metrics per sampled training image.
- `label_distribution.csv`: class counts and percentages for train/val splits.
- `robustness_metrics.csv`: PSNR/SSIM metrics for perturbed images.
- `test_anomaly_scores.csv`: anomaly detection outputs for the public test split.
Analysis Tables (`analysis/tables/`)
------------------------------------
CSV exports of structured metrics for spreadsheet or notebook use.
- `test_characterization_summary.csv`: pixel, edge, texture, and anomaly metrics per split.
- `train_image_stats.csv`, `val_image_stats.csv`: per-image pixel statistics for train/val splits.

Model Artifacts (`models/`)
---------------------------
Outputs and diagnostics produced by training runs under `src/models/`.

- `resnet18_baseline_weights.pth`: trained weights for the baseline ResNet18 classifier.
- `resnet18_baseline_summary.json`: hyperparameters, dataset sizes, and final validation accuracy for the baseline model.
- `confusion_matrix.npy`: raw confusion matrix from the ResNet18 baseline evaluation.
- `per_class_accuracy.json`: per-class validation accuracy from the ResNet18 baseline evaluation.
- `difficult_pairs.csv`: misclassification counts sorted by severity for the baseline model.
- `test_predictions.csv`: logits, class probabilities, and top-1 predictions generated by `baseline_resnet.py`.
- `training_curves_baseline.png`: learning curves (loss and accuracy) for the baseline training run.
